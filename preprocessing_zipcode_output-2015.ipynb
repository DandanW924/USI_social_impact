{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This loads and integrates PLUTO, FDNY, DOB/ECB, and ACS data and aggregates to the zipcode level. It truncates the data to include 2015 data, which impacts FDNY, DOB/ECB datasets.\n",
    "\n",
    "# Use this output of zips by features (195 x 735 matrix) will be used for final model evaluation. Only the target variable (gas leaks per zip for all of 2015) is really needed, but this processes all 2015 data in case we want to do time series analysis later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import pickle\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global variables for data pathfiles\n",
    "\n",
    "FDNY_RAW = \"raw_data/Incidents_Responded_to_by_Fire_Companies.csv\"\n",
    "NYC_ZIPS = 'raw_data/NYC_ZIPS/ZIP_CODE_040114.shp'\n",
    "PLUTO_BK = 'raw_data/PLUTO/Brooklyn/BKMapPLUTO.shp'\n",
    "PLUTO_BX = 'raw_data/PLUTO/Bronx/BXMapPLUTO.shp'\n",
    "PLUTO_MN = 'raw_data/PLUTO/Manhattan/MNMapPLUTO.shp'\n",
    "PLUTO_QN = 'raw_data/PLUTO/Queens/QNMapPLUTO.shp'\n",
    "PLUTO_SI = 'raw_data/PLUTO/Staten_Island/SIMapPLUTO.shp'\n",
    "MASTER_PLUTO_PICKLE = 'processed_data/master_pluto.pickle'\n",
    "DOB_COMPLAINTS = 'raw_data/DOB_Complaints_Received.csv'\n",
    "DOB_ECB = 'raw_data/DOB_ECB_Violations.csv'\n",
    "DOB_VIOLATIONS = 'raw_data/DOB_Violations.csv'\n",
    "DOB_PERMITS = 'raw_data/Historical_DOB_Permit_Issuance.csv'\n",
    "PAD = 'raw_data/PAD/bobaadr.txt'\n",
    "CENSUS_TRACT_RACE = 'raw_data/CENSUS_TRACT_RACE_INCOME/ACS_15_5YR_DP05_with_ann.csv'\n",
    "CENSUS_TRACT_INCOME = 'raw_data/CENSUS_TRACT_RACE_INCOME/ACS_15_5YR_S1901_with_ann.csv'\n",
    "ZIP_TRACT = 'raw_data/zip_tract_122015.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FDNY data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import FDNY data\n",
    "fdny = pd.read_csv(FDNY_RAW,usecols=['IM_INCIDENT_KEY','INCIDENT_DATE_TIME',\n",
    "                                     'INCIDENT_TYPE_DESC','ZIP_CODE'],\n",
    "                   dtype={'ZIP_CODE':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NYC zip code and census tract shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import NYC zipcode shapefiles\n",
    "nyc_zips = gp.read_file(NYC_ZIPS)\n",
    "\n",
    "# read in zip_tract\n",
    "zip_tract = pd.read_csv(ZIP_TRACT,usecols=['ZIP','TRACT'],dtype={'ZIP':str,'TRACT':str})\n",
    "zip_tract.rename(columns = {'ZIP':'ZIPCODE'},inplace=True)\n",
    "\n",
    "# merge to nyc zips\n",
    "zip_tract_nyc = nyc_zips.merge(zip_tract,how='left',on='ZIPCODE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NYC PLUTO (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_filter_pluto():\n",
    "    \n",
    "    # import PLUTO for 5 boros\n",
    "    BK = gp.read_file(PLUTO_BK)\n",
    "    BX = gp.read_file(PLUTO_BX)\n",
    "    MN = gp.read_file(PLUTO_MN)\n",
    "    QN = gp.read_file(PLUTO_QN)\n",
    "    SI = gp.read_file(PLUTO_SI)\n",
    "    \n",
    "    # merge 5 boro PLUTO datasets \n",
    "    pluto_agg = BK.append(BX)\n",
    "    pluto_agg = pluto_agg.append(MN)\n",
    "    pluto_agg = pluto_agg.append(QN)\n",
    "    pluto_agg = pluto_agg.append(SI)\n",
    "    \n",
    "    # select key columns\n",
    "\n",
    "    pluto_select = pluto_agg[['ZipCode',\n",
    "    'BldgClass',\n",
    "    'LandUse',\n",
    "    'BldgArea',\n",
    "    'ComArea',\n",
    "    'ResArea',\n",
    "    'OfficeArea',\n",
    "    'RetailArea',\n",
    "    'UnitsRes',\n",
    "    'UnitsTotal',\n",
    "    'AssessTot',\n",
    "    'YearBuilt',\n",
    "    'BuiltFAR','LotArea']]\n",
    "    \n",
    "    # create pickle\n",
    "\n",
    "    with open(MASTER_PLUTO_PICKLE, 'wb') as handle:\n",
    "        pickle.dump(pluto_select, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists. Loading pickle...\n"
     ]
    }
   ],
   "source": [
    "# ***********************\n",
    "# NOTE: Since Geopandas does not allow filtering select columns, \n",
    "# you'll have to load full PLUTO set, merge, and select columns,\n",
    "# then save as a pickle file for later use.\n",
    "# ***********************\n",
    "\n",
    "if os.path.exists(MASTER_PLUTO_PICKLE):\n",
    "    print \"File exists. Loading pickle...\"\n",
    "    # load pickle of PLUTO data\n",
    "    with open(MASTER_PLUTO_PICKLE, 'rb') as handle:\n",
    "        master_pluto = pickle.load(handle)\n",
    "    \n",
    "else:\n",
    "    print \"File does not yet exist. Importing and filtering PLUTO. This could take several minutes...\"\n",
    "    # first time only, import, filter, and save processed PLUTO as a pickle for future use\n",
    "    import_filter_pluto()\n",
    "    \n",
    "    # load pickle of PLUTO data\n",
    "    with open(MASTER_PLUTO_PICKLE, 'rb') as handle:\n",
    "        master_pluto = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOB and ECB permits and violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DOB complaints\n",
    "dob_complaints = pd.read_csv(DOB_COMPLAINTS,usecols=['Complaint Number', 'Date Entered', \n",
    "                                 'BIN', 'Complaint Category', \n",
    "                                 'Disposition Date','Disposition Code', \n",
    "                                 'Inspection Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DOB violations \n",
    "dob_violations = pd.read_csv(DOB_VIOLATIONS,dtype={'BORO':str,\n",
    "                                                   'BLOCK':str,'LOT':str,\n",
    "                                                   'ISSUE_DATE':str,\n",
    "                                                   'DISPOSITION_DATE':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Daynan/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# ECB violations\n",
    "ecb = pd.read_csv(DOB_ECB,usecols=['BIN','BORO','BLOCK','LOT','SEVERITY','VIOLATION_TYPE',\n",
    "                                   'VIOLATION_DESCRIPTION',\n",
    "                                   'INFRACTION_CODE1','ISSUE_DATE',\n",
    "                                   'SECTION_LAW_DESCRIPTION1'],dtype={'BORO':str,\n",
    "                                                                      'BLOCK':str,\n",
    "                                                                      'LOT':str,\n",
    "                                                                      'ISSUE_DATE':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DOB work permits\n",
    "permits = pd.read_csv(DOB_PERMITS,usecols=['Zip Code','BOROUGH','Block','Lot',\n",
    "                                           'Bldg Type','Residential','Permit Type',\n",
    "                                           'Oil Gas','Issuance Date'],dtype={'BOROUGH':str,\n",
    "                                                                           'Block':str,\n",
    "                                                                           'Lot':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# race data\n",
    "race = pd.read_csv(CENSUS_TRACT_RACE,skiprows=[1],usecols=['GEO.id2', 'HC01_VC03', \n",
    "                                                           'HC01_VC49', 'HC01_VC50', \n",
    "                                                           'HC01_VC51','HC01_VC56', \n",
    "                                                           'HC01_VC64', 'HC01_VC69', 'HC01_VC23'])\n",
    "\n",
    "# rename columns\n",
    "race.rename(columns={'HC01_VC03': 'TOTAL_POPULATION', 'HC01_VC49': 'WHITE',\n",
    "                        'HC01_VC50': 'BLACK_AFRICAN_AMERICAN', 'HC01_VC51': 'AMERICAN_INDIAN_AND_ALASKA_NATIVE',\n",
    "                        'HC01_VC56': 'ASIAN', 'HC01_VC64': 'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER',\n",
    "                        'HC01_VC69': 'SOME_OTHER_RACE', 'HC01_VC23': 'MEDIAN_AGE', 'GEO.id2': 'GEOID'}, inplace=True)\n",
    "\n",
    "# convert values to float\n",
    "def make_float(expected_float):\n",
    "    try:\n",
    "        if type(expected_float) == str:\n",
    "            expected_float = expected_float.replace('+', '').replace(',', '')\n",
    "        return float(expected_float)\n",
    "    except:\n",
    "        # print expected_float\n",
    "        return np.nan\n",
    "\n",
    "for i in race.columns[race.columns!='GEOID']:\n",
    "    race[i] = race[i].apply(lambda x: make_float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# income data\n",
    "income = pd.read_csv(CENSUS_TRACT_INCOME,skiprows=[1],usecols=['GEO.id2', 'HC01_EST_VC01', 'HC01_EST_VC15'])\n",
    "\n",
    "# rename columns\n",
    "income.rename(columns={'HC01_EST_VC01': 'TOTAL_HOUSEHOLDS', \n",
    "                       'HC01_EST_VC15': 'MEAN_INCOME', 'GEO.id2': 'GEOID'}, inplace=True)\n",
    "\n",
    "#convert values to float\n",
    "for i in income.columns[income.columns!='GEOID']:\n",
    "    income[i] = income[i].apply(lambda x: make_float(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATE SELECTION: HOLD OUT 2015 FOR FINAL EVALUATION\n",
    "Time-sensitive datasets: FDNY, DOB/ECB\n",
    "\n",
    "We'll assume the same PLUTO and ACS variables stand for all years.\n",
    "\n",
    "** Note that the DOB Work Permits data does not extend past 2013, but we're including it given the assumption that historical work permits still apply to buildings existing in 2013-2015 and could be factors. (Exceptions clearly would occur to this assumption). So we will use the same historical data (work permits through 2013) for both training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep datatime fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert fdny datetime\n",
    "fdny['incident_date'] = fdny['INCIDENT_DATE_TIME'].apply(\n",
    "    lambda x: datetime.datetime.strptime(x.split(' ')[0],'%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dob/ecb date conversion\n",
    "dob_complaints['date_entered'] = dob_complaints['Date Entered'].apply(\n",
    "    lambda x: datetime.datetime.strptime(x,'%m/%d/%Y'))\n",
    "\n",
    "permits['issuance_date'] = permits['Issuance Date'].apply(\n",
    "    lambda x: datetime.datetime.strptime(x,'%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deal with inconsistent datetime\n",
    "def dob_date(data):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(data, '%Y%m%d')\n",
    "    except:\n",
    "        try:\n",
    "            y,md = data.split('  ')\n",
    "            if y in ['11','12','13','14','15']:\n",
    "                data = '20'+y+md\n",
    "                return datetime.datetime.strptime(data, '%Y%m%d')\n",
    "        except:\n",
    "            try:\n",
    "                data = str(data)[:8]\n",
    "                return datetime.datetime.strptime(data, '%Y%m%d')\n",
    "            except:\n",
    "                return float(\"NaN\")\n",
    "            \n",
    "dob_violations['issue_date'] = dob_violations['ISSUE_DATE'].apply(\n",
    "    lambda x: dob_date(x))\n",
    "\n",
    "# cut out records with incoherent date format or years before 2013\n",
    "dob_violations = dob_violations[~dob_violations['issue_date'].isnull()]\n",
    "dob_violations['issue_date'] = dob_violations['issue_date'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deal with inconsistent datetime\n",
    "def ecb_date(data):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(str(data), '%Y%m%d')\n",
    "    except:\n",
    "        return float(\"NaN\")\n",
    "\n",
    "ecb['issue_date'] = ecb['ISSUE_DATE'].apply(\n",
    "    lambda x: ecb_date(x))\n",
    "\n",
    "# cut out the 85 records with incoherent date format\n",
    "ecb = ecb[~ecb['issue_date'].isnull()]           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dates for 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# date filter method\n",
    "def filter_date(data, date_col): \n",
    "    start_date = datetime.date(2015,1,1)\n",
    "    end_date = datetime.date(2016,1,1) # not inclusive of end date\n",
    "    \n",
    "    # truncate to selected dates\n",
    "    return data[(data[date_col]>=start_date) & (data[date_col]<end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# segment data by date\n",
    "fdny_sliced = filter_date(fdny,'incident_date')\n",
    "dob_complaints_sliced = filter_date(dob_complaints,'date_entered')\n",
    "dob_violations_sliced = filter_date(dob_violations,'issue_date')\n",
    "ecb_sliced = filter_date(ecb,'issue_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter, aggregate and scale data\n",
    "\n",
    "- Filter FDNY by gas leaks\n",
    "- Aggregate FDNY by zip codes\n",
    "- Preprocess and scale PLUTO attributes\n",
    "- Aggregate PLUTO data by zip\n",
    "- Preprocess and scale building data attributes\n",
    "- Aggregate building data by zip \n",
    "- Aggregate census tract data by zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter FDNY for gas leaks and aggregate by zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Daynan/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# split incident description to get code, filter\n",
    "def code_split(data):\n",
    "    a = data.split(' -')\n",
    "    return a[0]\n",
    "\n",
    "fdny_sliced['incident_code'] = fdny_sliced.INCIDENT_TYPE_DESC.apply(lambda x: code_split(x))\n",
    "fdny_gas = fdny_sliced[fdny_sliced.incident_code=='412'].copy()\n",
    "\n",
    "# clean FDNY zip data and aggregate by zip\n",
    "fdny_gas_zip = pd.DataFrame(fdny_gas.groupby('ZIP_CODE')[\n",
    "        'IM_INCIDENT_KEY'].count()).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess and scale PLUTO attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert PLUTO zip to string\n",
    "master_pluto['ZipCode'] = master_pluto['ZipCode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate building age\n",
    "# note: to keep equal comparison b/t train and test we're keeping age as of 2013 for both\n",
    "def year_calc(data):\n",
    "    if (data < 1800) | (data > 2016):\n",
    "        return float('NaN')\n",
    "    else:\n",
    "        return 2013-data \n",
    "    \n",
    "master_pluto['age'] = master_pluto.YearBuilt.apply(lambda x: year_calc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_and_group_zip(data,zip_col_name,field,multiple=True,\n",
    "                        header_prefix=None,dispose=False,og=False,annualize_it=False):\n",
    "    '''Creates a general \"group by\" and scaling function that:\n",
    "    - groups data for a given variable category in an input dataframe by zip code\n",
    "    - then creates a ratio of each variable category in the zip for all values in zip\n",
    "    - produces a new sparse matrix with rows=zip codes and cols=each category of the variable,\n",
    "    where the values are the ratio of the category / all instances in the zip\n",
    "    '''\n",
    "    # group selected variable by zip code\n",
    "    if multiple:\n",
    "        if og:\n",
    "            data2 = data.copy()\n",
    "            data2[field] = data2[field].fillna('NA')\n",
    "            data = data2.copy()\n",
    "        \n",
    "        temp_df = data.groupby([zip_col_name,field])[\n",
    "            field].count().unstack(level=-1).reset_index()\n",
    "        \n",
    "        # create df of ratio of select category of variable per all instances in zip\n",
    "        zip_matrix = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(temp_df[zip_col_name])):\n",
    "            zip_matrix[str(\n",
    "                temp_df[zip_col_name][i])] = temp_df.T[i][1:]/temp_df.T[i][1:].sum()\n",
    "            \n",
    "        # to catch training data\n",
    "        if annualize_it:\n",
    "            zip_matrix = zip_matrix.astype(float)/2\n",
    "    \n",
    "        zip_matrix = zip_matrix.T.reset_index()\n",
    "\n",
    "        zip_matrix['ZipCode'] = zip_matrix['index'].astype(str)\n",
    "        if og:\n",
    "            zip_matrix = zip_matrix.drop(['index','NA'],axis=1)\n",
    "        else:\n",
    "            zip_matrix = zip_matrix.drop('index',axis=1)\n",
    "        \n",
    "        if dispose:\n",
    "            zip_matrix = zip_matrix.rename(columns={zip_matrix.columns[0]:'No_disposition'})\n",
    "            \n",
    "        # catch decimal zipcodes and strip\n",
    "        if len(zip_matrix.ZipCode[10])>5:\n",
    "            zip_matrix['ZipCode'] = zip_matrix['ZipCode'].apply(lambda x: x[:-2])\n",
    "\n",
    "        \n",
    "        # update header to specific source data (for less confusion when merging data later)\n",
    "        if header_prefix:\n",
    "            new_columns = []\n",
    "            for col in zip_matrix.columns:\n",
    "                if col != 'ZipCode':\n",
    "                    new_columns.append(header_prefix+col)\n",
    "                else:\n",
    "                    new_columns.append(col)\n",
    "            zip_matrix.columns = new_columns\n",
    "            \n",
    "        return zip_matrix       \n",
    "    \n",
    "    else:\n",
    "    \n",
    "        return pd.DataFrame((data.groupby(zip_col_name)[field].sum())/data.groupby(\n",
    "                zip_col_name)[field].count()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# groupby zip - average age\n",
    "avg_bldg_age_by_zip = scale_and_group_zip(master_pluto,'ZipCode','age',multiple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# groupby zip - # building class in zip / total building in zip\n",
    "bldgclass_by_zip = scale_and_group_zip(master_pluto,'ZipCode','BldgClass',\n",
    "                                       multiple=True,header_prefix='bldg_class_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# groupby zip - # landuse in zip / total land uses in zip\n",
    "landuse_by_zip = scale_and_group_zip(master_pluto,'ZipCode','LandUse',\n",
    "                                       multiple=True,header_prefix='landuse_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the following assorted pluto attributes are aggregated by zip\n",
    "pluto_attrib_by_zip = pd.DataFrame()\n",
    "\n",
    "# function to create ratio of given PLUTO category per zip code\n",
    "def pluto_attributes_zip(data,zip_col_name,oldfield,newfield,denominator='BldgArea'):\n",
    "    pluto_attrib_by_zip[newfield] = data.groupby(\n",
    "        zip_col_name)[oldfield].sum()*1.0/data.groupby(zip_col_name)[denominator].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# commercial ratio by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','ComArea','com_ratio',denominator='BldgArea')\n",
    "\n",
    "# residential ratio by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','ResArea','res_ratio',denominator='BldgArea')\n",
    "\n",
    "# office ratio by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','OfficeArea','office_ratio',denominator='BldgArea')\n",
    "\n",
    "# retail ratio by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','RetailArea','retail_ratio',denominator='BldgArea')\n",
    "\n",
    "# res / total units by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','UnitsRes','res_unit_ratio',denominator='UnitsTotal')\n",
    "\n",
    "# mean unit area by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','BldgArea','unit_area',denominator='UnitsTotal')\n",
    "\n",
    "# assessed value per sq foot\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','AssessTot','value_per_ft',denominator='LotArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total units by zip code\n",
    "pluto_attrib_by_zip['total_units'] = master_pluto.groupby('ZipCode')['UnitsTotal'].sum()\n",
    "\n",
    "# reset index\n",
    "pluto_attrib_by_zip = pluto_attrib_by_zip.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess and scale the DOB and ECB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge BIN with zipcodes pulled from another dataset\n",
    "pad = pd.read_csv(PAD,usecols=['bin','zipcode'])\n",
    "# zip to int\n",
    "def zipint(data):\n",
    "    try:\n",
    "        return str(int(data))\n",
    "    except ValueError:\n",
    "        return float('NaN')\n",
    "pad['zipcode'] = pad.zipcode.apply(lambda x: zipint(x))\n",
    "pad = pad.rename(columns={'bin':'BIN'})\n",
    "pad = pad[~pad.zipcode.isnull()]\n",
    "pad = pad.drop_duplicates(\"BIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge zip to dob/ecb datasets\n",
    "dob_complaints_sliced2 = dob_complaints_sliced.merge(pad,how='left',on='BIN')\n",
    "dob_violations_sliced2 = dob_violations_sliced.merge(pad,how='left',on='BIN')\n",
    "ecb_sliced2 = ecb_sliced.merge(pad,how='left',on='BIN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process DOB/ECB data as with the PLUTO data (group by zip and scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: For training set, this will aggregate the values to the zipcode level, and then divide by 2, thereby producing a value for each zipcode as an average per year over the two years. For the test set, it will not divide by 2 as the test data is all for 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same as above, group various DOB / ECB datasets to zip and scale\n",
    "\n",
    "# groupby zip - # complaint category in zip / total complaints in zip\n",
    "complaints_by_zip = scale_and_group_zip(dob_complaints_sliced2,'zipcode','Complaint Category',\n",
    "                                       multiple=True,header_prefix='DOB_complaint_')\n",
    "\n",
    "# groupby zip - # disposition code in zip / total dispositions in zip\n",
    "disposition_by_zip = scale_and_group_zip(dob_complaints_sliced2,'zipcode','Disposition Code',\n",
    "                                       multiple=True,header_prefix='DOB_dispos_',dispose=True)\n",
    "\n",
    "# groupby zip - # dob violations type in zip / total violations in zip\n",
    "violations_by_zip = scale_and_group_zip(dob_violations_sliced2,'zipcode','VIOLATION_TYPE',\n",
    "                                       multiple=True,header_prefix='DOB_violation_')\n",
    "\n",
    "# groupby zip - # ecb violation type in zip / total violations in zip\n",
    "ecb_violations_by_zip = scale_and_group_zip(ecb_sliced2,'zipcode','VIOLATION_TYPE',\n",
    "                                      multiple=True,header_prefix='ECB_violation_')\n",
    "\n",
    "# groupby zip - # ecb violation type in zip / total violations in zip\n",
    "ecb_infractions_by_zip = scale_and_group_zip(ecb_sliced2,'zipcode','INFRACTION_CODE1',\n",
    "                                       multiple=True,header_prefix='ECB_infraction_')\n",
    "\n",
    "# groupby zip - # permit type in zip / total permits in zip\n",
    "permit_by_zip = scale_and_group_zip(permits,'Zip Code','Permit Type',\n",
    "                                       multiple=True,header_prefix='DOB_permit_')\n",
    "\n",
    "# groupby zip - # oil or gas permits in zip / total permits in zip\n",
    "oil_gas_permit_by_zip = scale_and_group_zip(permits,'Zip Code','Oil Gas',\n",
    "                                           multiple=True,header_prefix='DOB_permit_',og=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process census data and aggregate by zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge race and income\n",
    "census = race.merge(income,how='outer',on='GEOID')\n",
    "\n",
    "# add zip code column\n",
    "census['TRACT'] = census.GEOID.apply(lambda x: str(x))\n",
    "\n",
    "census_zip = census.merge(zip_tract_nyc,how='inner',on='TRACT')\n",
    "\n",
    "census_zip.rename(columns={'ZIPCODE':'zipcode'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the following assorted census attributes are aggregated by zip\n",
    "census_features_by_zip = pd.DataFrame()\n",
    "\n",
    "# function to create ratio of given PLUTO category per zip code\n",
    "def agg_census_zip(data,zip_col_name,oldfield,newfield,denominator='TOTAL_POPULATION'):\n",
    "    census_features_by_zip[newfield] = data.groupby(\n",
    "        zip_col_name)[oldfield].sum()*1.0/data.groupby(zip_col_name)[denominator].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same as above, group various census data to zip and scale\n",
    "\n",
    "# groupby zip: total population in zip\n",
    "census_features_by_zip['total_population'] = census_zip.groupby('zipcode')['TOTAL_POPULATION'].sum()\n",
    "\n",
    "# groupby zip: total households in zip\n",
    "census_features_by_zip['total_households'] = census_zip.groupby('zipcode')['TOTAL_HOUSEHOLDS'].sum()\n",
    "\n",
    "# demo data by zip: race population / total population of zip\n",
    "for col in census_zip.columns[3:9]:\n",
    "    agg_census_zip(census_zip,'zipcode',col,col+'_ratio','TOTAL_POPULATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aggregate income by mutliplying mean income for census tract by total households in tract\n",
    "# to get total projected income for the tract\n",
    "# then aggregate total income to zipcode level and divide that by total households aggregated to zip\n",
    "# to get a mean income per household for the zip\n",
    "\n",
    "census_zip['total_income'] = census_zip['MEAN_INCOME']*census_zip['TOTAL_HOUSEHOLDS']\n",
    "\n",
    "census_features_by_zip['zip_household_mean_income'] = census_zip.groupby(\n",
    "    'zipcode')['total_income'].sum()*1.0/census_zip.groupby('zipcode')['TOTAL_HOUSEHOLDS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set zipcode as column for later merge\n",
    "\n",
    "census_features_by_zip.reset_index(inplace=True)\n",
    "census_features_by_zip = census_features_by_zip.rename(columns={'zipcode':'ZipCode'}).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the NYC zipcode shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove duplicate zips (just keeping first listed)\n",
    "index_list = []\n",
    "for i in nyc_zips.ZIPCODE:\n",
    "    temp_index = nyc_zips.ZIPCODE[nyc_zips.ZIPCODE==i].index.tolist()\n",
    "\n",
    "    if len(temp_index)>1:\n",
    "        index_list += temp_index[1:]\n",
    "\n",
    "index_list = set(index_list)\n",
    "\n",
    "zip_t = nyc_zips.T\n",
    "\n",
    "zip_drop = zip_t.drop(index_list,axis=1)\n",
    "\n",
    "nyc_zips_set = zip_drop.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge gas\n",
    "fdny_gas_zip['ZipCode'] = fdny_gas_zip['ZIP_CODE'].astype(str)\n",
    "fdny_gas_zip['gas_incidents'] = fdny_gas_zip['IM_INCIDENT_KEY']\n",
    "fdny_gas_zip_2 = fdny_gas_zip.drop(['ZIP_CODE','IM_INCIDENT_KEY'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, since FDNY zips are a subset of PLUTO zips, merging all PLUTO first, then performing left-join of FDNY on PLUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge PLUTO datasets\n",
    "\n",
    "# age and building class\n",
    "merged_pluto = avg_bldg_age_by_zip.merge(bldgclass_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# merge land use\n",
    "merged_pluto = merged_pluto.merge(landuse_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# merge remaing PLUTO attributes\n",
    "merged_pluto = merged_pluto.merge(pluto_attrib_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# merge with FDNY\n",
    "pluto_fdny = merged_pluto.merge(fdny_gas_zip_2, how = 'left',on='ZipCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge DOB / ECB data\n",
    "\n",
    "# dob complaints\n",
    "pluto_fdny_dob = pluto_fdny.merge(complaints_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# dob dispositions\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(disposition_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# dob violations\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(violations_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# ecb violations\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(ecb_violations_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# ecb infractions\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(ecb_infractions_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# dob permit type\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(permit_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# dob oil or gas permit\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(oil_gas_permit_by_zip,how='left',on='ZipCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge census data\n",
    "pluto_fdny_dob_census = pluto_fdny_dob.merge(census_features_by_zip,how='left',on='ZipCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge zip shapefiles\n",
    "nyc_zips_set['ZipCode'] = nyc_zips_set['ZIPCODE'].astype(str)\n",
    "nyc_zips_clean = nyc_zips_set[['ZipCode','geometry','AREA']].copy()\n",
    "\n",
    "master_merged = pluto_fdny_dob_census.merge(nyc_zips_clean,how='left',on='ZipCode')\n",
    "\n",
    "# move target (i.e. dependent) variable to last column and rename \"total_gas_incidents\"\n",
    "master_merged['total_gas_incidents_yr'] = master_merged['gas_incidents']\n",
    "    \n",
    "del master_merged['gas_incidents']\n",
    "\n",
    "# add column gas incidents per building unit\n",
    "master_merged['gas_incidents_per_bldg_unit'] = master_merged[\n",
    "    'total_gas_incidents_yr']*1.0/master_merged['total_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_merged.to_csv('processed_data/pluto_fdny_dob_census_to_zipcode_2015.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT: final merged \n",
    "\n",
    "#### FDNY\n",
    "- Merge with zip code shapefile\n",
    "\n",
    "#### PLUTO features\n",
    "- Avg building age per zipcode\n",
    "- Ratio of each building class per zip code\n",
    "- Ratio of each land use per zip code\n",
    "- Building use ratio (commercial, residential, office, retail) per zip code\n",
    "- Residential unit density per zip code\n",
    "- Ave Unit area per zip code\n",
    "- Value per ft per zip code\n",
    "- Total units per zip code\n",
    "\n",
    "#### DOB/ECB features\n",
    "- Ratio of each DOB complaint type per zip code\n",
    "- Ratio of each DOB complaint disposition per zip code\n",
    "- Ratio of each DOB violation type per zip code\n",
    "- Ratio of each ECB violation type per zip code\n",
    "- Ratio of each DOB work permit type per zip code\n",
    "- Ratio of oil or gas permits out of all permits per zip code\n",
    "\n",
    "#### Census data features\n",
    "- Total population per zip code\n",
    "- Total households per zip code\n",
    "- Mean income (calculated by: mean income per census tract * total households in ct to get total income per ct, \n",
    "    then aggregate total income to zip code and divide by total households aggregated to zip code\n",
    "- Ratio of various racial groups out of total population per zip code\n",
    "\n",
    "#### Target variables (last two columns in the output dataset)\n",
    "- Total gas incidents per zip code\n",
    "- Ratio of gas incidents per total building units in zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
