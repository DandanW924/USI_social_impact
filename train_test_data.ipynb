{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.preprocessing import MinMaxScaler # Look at RF for package\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "np.random.seed(20170301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zipcode train, test, predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get 2013, 2014, and 2015 data for zipcode\n",
    "\n",
    "init_zip_2013 = pd.read_csv('outputs/pluto_fdny_dob_census_to_zipcode_2013.csv')\n",
    "init_zip_2014 = pd.read_csv('outputs/pluto_fdny_dob_census_to_zipcode_2014.csv')\n",
    "init_zip_2015 = pd.read_csv('outputs/pluto_fdny_dob_census_to_zipcode_2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^^^ DJC NOTE: I've changed the name of the initialized dataframes here and created copies below keep from over-writing them when you drop the columns, like \"geometry\" and later \"zipcode\" from the features and target matrices. Now you can easily merge your predicted gas leaks per zip back to this initial df that has zip code number and geometry for mapping, etc. (and the index is unchanged, so rows should be in exact same order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create copies of initial dfs for further manipulation\n",
    "zip_2013 = init_zip_2013.copy()\n",
    "zip_2014 = init_zip_2014.copy()\n",
    "zip_2015 = init_zip_2015.copy()\n",
    "\n",
    "\n",
    "# Cleaning non-numeric columns\n",
    "# remove nan's and inf's (turn to 0)\n",
    "\n",
    "zip_2013.fillna(0, inplace=True)\n",
    "zip_2013 = zip_2013.replace(np.inf, 0)\n",
    "zip_2013 = zip_2013[~zip_2013['ZipCode'].isin(['0', 0])]    \n",
    "zip_2014.fillna(0, inplace=True)\n",
    "zip_2014 = zip_2014.replace(np.inf, 0)\n",
    "zip_2014 = zip_2014[~zip_2014['ZipCode'].isin(['0', 0])]\n",
    "zip_2015.fillna(0, inplace=True)\n",
    "zip_2015 = zip_2015.replace(np.inf, 0)\n",
    "zip_2015 = zip_2015[~zip_2015['ZipCode'].isin(['0', 0])]\n",
    "for i in ['geometry', 'AREA', 'total_gas_incidents']:\n",
    "    del zip_2013[i]\n",
    "    del zip_2014[i]\n",
    "    del zip_2015[i]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# processing columns to be in the same order. \n",
    "# if 2014 does not have a column from 2013, \n",
    "# 0's will be filled for the entire column \n",
    "\n",
    "zip_cols_2013 = zip_2013.columns.tolist()\n",
    "for i in zip_cols_2013:\n",
    "    if i not in zip_2014.columns:\n",
    "        zip_2014[i] = 0.0\n",
    "        \n",
    "# place 2014 columns in the same order - droppping cols that did not appear in 2013.\n",
    "zip_2014 = zip_2014[zip_cols_2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validation that zip code orders are the same for our train and test set\n",
    "\n",
    "for idx, i in enumerate(zip_2013.iloc[:,0].values):\n",
    "    if zip_2014.iloc[:,0].values[idx] != i:\n",
    "        print i\n",
    "\n",
    "for idx, i in enumerate(zip_2014.iloc[:,0].values):\n",
    "    if zip_2015.iloc[:,0].values[idx] != i:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train will be 2013 features, y_train will be 2013 gas_leaks_per_bldg_unit\n",
    "X_train_zip = zip_2013.iloc[:,1:-1].values\n",
    "y_train_zip = zip_2013.iloc[:,-1].values\n",
    "\n",
    "\n",
    "# min/max scalling of feature data\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_zip = min_max_scaler.fit_transform(X_train_zip)\n",
    "\n",
    "# X_test will be 2013 features, y_test will be 2014 gas_leaks_per_bldg_unit\n",
    "X_test_zip = X_train_zip\n",
    "y_test_zip = zip_2014.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DJC NOTE: Someone should actually try doing some Bayesian inference here -- and instead of fitting the X_pred_zip (i.e. 2014) features with MinMaxScaler, actually use parameters learned from the 2013 training set (i.e. prior distribution) and model the change in distribution learned from the 2014 data when cross-validating...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create prediction features and dependent variable - zip\n",
    "\n",
    "X_pred_zip = zip_2014.iloc[:,1:-1].values\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_pred_zip = min_max_scaler.fit_transform(X_pred_zip)\n",
    "\n",
    "y_pred_zip = zip_2015.iloc[:,-1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 720) (194, 720) (194, 720)\n"
     ]
    }
   ],
   "source": [
    "print X_train_zip.shape, X_test_zip.shape, X_pred_zip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194,) (194,) (194,)\n"
     ]
    }
   ],
   "source": [
    "print y_train_zip.shape, y_test_zip.shape, y_pred_zip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# naive model 2013 to predict 2014\n",
    "\n",
    "# y_test_zip - y_train_zip # calculate error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tract train, test, predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get 2013, 2014, and 2015 data for zipcode\n",
    "\n",
    "init_tract_2013 = pd.read_csv('outputs/pluto_fdny_dob_census_to_tract_2013.csv')\n",
    "init_tract_2014 = pd.read_csv('outputs/pluto_fdny_dob_census_to_tract_2014.csv')\n",
    "init_tract_2015 = pd.read_csv('outputs/pluto_fdny_dob_census_to_tract_2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^^^ DJC NOTE #1: As before, I've changed the name of the initialized dataframes here and created copies below.\n",
    "\n",
    "### NOTE #2: While before, zip codes were really the index for the observations (and Nate dropped them from the features appropriately), for the tract-level, they actually serve as categorical features that are a rough approximation of geographic proximity and likely have some influence in terms of predicting gas leaks. Not likely better than spatial autocorrelation, but food for thought in case someone tries including zips as features (you'd have to convert to one-hot vector)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy initial dfs\n",
    "tract_2013 = init_tract_2013.copy()\n",
    "tract_2014 = init_tract_2014.copy()\n",
    "tract_2015 = init_tract_2015.copy()\n",
    "\n",
    "\n",
    "# Cleaning non-numeric columns\n",
    "# remove nan's and inf's (turn to 0)\n",
    "\n",
    "tract_2013.fillna(0, inplace=True)\n",
    "tract_2013 = tract_2013.replace(np.inf, 0)\n",
    "tract_2014.fillna(0, inplace=True)\n",
    "tract_2014 = tract_2014.replace(np.inf, 0)\n",
    "tract_2015.fillna(0, inplace=True)\n",
    "tract_2015 = tract_2015.replace(np.inf, 0)\n",
    "for i in ['NTACode', 'NTAName', 'geometry', 'ZipCode', 'total_gas_incidents', 'GEOID']:\n",
    "    del tract_2013[i]\n",
    "    del tract_2014[i]\n",
    "    del tract_2015[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# processing columns to be in the same order. \n",
    "# if 2014 does not have a column from 2013, \n",
    "# 0's will be filled for the entire column \n",
    "\n",
    "tract_cols_2013 = tract_2013.columns.tolist()\n",
    "for i in tract_cols_2013:\n",
    "    if i not in tract_2014.columns:\n",
    "        tract_2014[i] = 0.0\n",
    "        \n",
    "# place 2014 columns in the same order - droppping cols that did not appear in 2013.\n",
    "tract_2014 = tract_2014[tract_cols_2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation that tract orders are the same for our train, test, and predict sets\n",
    "\n",
    "for idx, i in enumerate(tract_2013.iloc[:,0].values):\n",
    "    if tract_2014.iloc[:,0].values[idx] != i:\n",
    "        print i\n",
    "\n",
    "for idx, i in enumerate(tract_2014.iloc[:,0].values):\n",
    "    if tract_2015.iloc[:,0].values[idx] != i:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train will be 2013 features, y_train will be 2013 gas_leaks_per_bldg_unit\n",
    "X_train_tract = tract_2013.iloc[:,1:-1].values\n",
    "y_train_tract = tract_2013.iloc[:,-1].values\n",
    "\n",
    "\n",
    "# min/max scalling of feature data\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_tract = min_max_scaler.fit_transform(X_train_tract)\n",
    "\n",
    "# X_test will be 2013 features, y_test will be 2014 gas_leaks_per_bldg_unit\n",
    "X_test_tract = X_train_tract\n",
    "y_test_tract = tract_2014.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create prediction features and dependent variable - tract\n",
    "\n",
    "X_pred_tract = tract_2014.iloc[:,1:-1].values\n",
    "\n",
    "# scaling of features \n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_pred_tract = min_max_scaler.fit_transform(X_pred_tract)\n",
    "\n",
    "y_pred_tract = tract_2015.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3180, 717) (3180, 717) (3180, 717)\n"
     ]
    }
   ],
   "source": [
    "print X_pred_tract.shape, X_train_tract.shape, X_test_tract.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3180,) (3180,) (3180,)\n"
     ]
    }
   ],
   "source": [
    "print y_train_tract.shape, y_test_tract.shape, y_pred_tract.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
