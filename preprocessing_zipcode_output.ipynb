{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import pickle\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global variables for data pathfiles\n",
    "\n",
    "FDNY_RAW = \"raw_data/Incidents_Responded_to_by_Fire_Companies.csv\"\n",
    "NYC_ZIPS = 'raw_data/NYC_ZIPS/ZIP_CODE_040114.shp'\n",
    "PLUTO_BK = 'raw_data/PLUTO/Brooklyn/BKMapPLUTO.shp'\n",
    "PLUTO_BX = 'raw_data/PLUTO/Bronx/BXMapPLUTO.shp'\n",
    "PLUTO_MN = 'raw_data/PLUTO/Manhattan/MNMapPLUTO.shp'\n",
    "PLUTO_QN = 'raw_data/PLUTO/Queens/QNMapPLUTO.shp'\n",
    "PLUTO_SI = 'raw_data/PLUTO/Staten_Island/SIMapPLUTO.shp'\n",
    "MASTER_PLUTO_PICKLE = 'processed_data/master_pluto.pickle'\n",
    "DOB_COMPLAINTS = 'raw_data/DOB_Complaints_Received.csv'\n",
    "DOB_ECB = 'raw_data/DOB_ECB_Violations.csv'\n",
    "DOB_VIOLATIONS = 'raw_data/DOB_Violations.csv'\n",
    "DOB_PERMITS = 'raw_data/Historical_DOB_Permit_Issuance.csv'\n",
    "PAD = 'raw_data/PAD/bobaadr.txt'\n",
    "CENSUS_TRACT_RACE = 'raw_data/CENSUS_TRACT_RACE_INCOME/ACS_15_5YR_DP05_with_ann.csv'\n",
    "CENSUS_TRACT_INCOME = 'raw_data/CENSUS_TRACT_RACE_INCOME/ACS_15_5YR_S1901_with_ann.csv'\n",
    "ZIP_TRACT = 'raw_data/zip_tract_122015.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FDNY data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import FDNY data\n",
    "fdny = pd.read_csv(FDNY_RAW,usecols=['IM_INCIDENT_KEY',\n",
    "                                     'INCIDENT_TYPE_DESC','ZIP_CODE'],\n",
    "                   dtype={'ZIP_CODE':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NYC zip code and census tract shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import NYC zipcode shapefiles\n",
    "nyc_zips = gp.read_file(NYC_ZIPS)\n",
    "\n",
    "# read in zip_tract\n",
    "zip_tract = pd.read_csv(ZIP_TRACT,usecols=['ZIP','TRACT'],dtype={'ZIP':str,'TRACT':str})\n",
    "zip_tract.rename(columns = {'ZIP':'ZIPCODE'},inplace=True)\n",
    "\n",
    "# merge to nyc zips\n",
    "zip_tract_nyc = nyc_zips.merge(zip_tract,how='left',on='ZIPCODE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NYC PLUTO (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_filter_pluto():\n",
    "    \n",
    "    # import PLUTO for 5 boros\n",
    "    BK = gp.read_file(PLUTO_BK)\n",
    "    BX = gp.read_file(PLUTO_BX)\n",
    "    MN = gp.read_file(PLUTO_MN)\n",
    "    QN = gp.read_file(PLUTO_QN)\n",
    "    SI = gp.read_file(PLUTO_SI)\n",
    "    \n",
    "    # merge 5 boro PLUTO datasets \n",
    "    pluto_agg = BK.append(BX)\n",
    "    pluto_agg = pluto_agg.append(MN)\n",
    "    pluto_agg = pluto_agg.append(QN)\n",
    "    pluto_agg = pluto_agg.append(SI)\n",
    "    \n",
    "    # select key columns\n",
    "\n",
    "    pluto_select = pluto_agg[['ZipCode',\n",
    "    'BldgClass',\n",
    "    'LandUse',\n",
    "    'BldgArea',\n",
    "    'ComArea',\n",
    "    'ResArea',\n",
    "    'OfficeArea',\n",
    "    'RetailArea',\n",
    "    'UnitsRes',\n",
    "    'UnitsTotal',\n",
    "    'AssessTot',\n",
    "    'YearBuilt',\n",
    "    'BuiltFAR','LotArea']]\n",
    "    \n",
    "    # create pickle\n",
    "\n",
    "    with open(MASTER_PLUTO_PICKLE, 'wb') as handle:\n",
    "        pickle.dump(pluto_select, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists. Loading pickle...\n"
     ]
    }
   ],
   "source": [
    "# ***********************\n",
    "# NOTE: Since Geopandas does not allow filtering select columns, \n",
    "# you'll have to load full PLUTO set, merge, and select columns,\n",
    "# then save as a pickle file for later use.\n",
    "# ***********************\n",
    "\n",
    "if os.path.exists(MASTER_PLUTO_PICKLE):\n",
    "    print \"File exists. Loading pickle...\"\n",
    "    # load pickle of PLUTO data\n",
    "    with open(MASTER_PLUTO_PICKLE, 'rb') as handle:\n",
    "        master_pluto = pickle.load(handle)\n",
    "    \n",
    "else:\n",
    "    print \"File does not yet exist. Importing and filtering PLUTO. This could take several minutes...\"\n",
    "    # first time only, import, filter, and save processed PLUTO as a pickle for future use\n",
    "    import_filter_pluto()\n",
    "    \n",
    "    # load pickle of PLUTO data\n",
    "    with open(MASTER_PLUTO_PICKLE, 'rb') as handle:\n",
    "        master_pluto = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOB and ECB permits and violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DOB complaints\n",
    "dob_complaints = pd.read_csv(DOB_COMPLAINTS,usecols=['Complaint Number', 'Date Entered', \n",
    "                                 'BIN', 'Complaint Category', \n",
    "                                 'Disposition Date','Disposition Code', \n",
    "                                 'Inspection Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DOB violations \n",
    "dob_violations = pd.read_csv(DOB_VIOLATIONS,dtype={'BORO':str,\n",
    "                                                   'BLOCK':str,'LOT':str,\n",
    "                                                   'ISSUE_DATE':str,\n",
    "                                                   'DISPOSITION_DATE':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Daynan/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# ECB violations\n",
    "ecb = pd.read_csv(DOB_ECB,usecols=['BIN','BORO','BLOCK','LOT','SEVERITY','VIOLATION_TYPE',\n",
    "                                   'VIOLATION_DESCRIPTION',\n",
    "                                   'INFRACTION_CODE1','ISSUE_DATE',\n",
    "                                   'SECTION_LAW_DESCRIPTION1'],dtype={'BORO':str,\n",
    "                                                                      'BLOCK':str,\n",
    "                                                                      'LOT':str,\n",
    "                                                                      'ISSUE_DATE':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DOB work permits\n",
    "permits = pd.read_csv(DOB_PERMITS,usecols=['Zip Code','BOROUGH','Block','Lot',\n",
    "                                           'Bldg Type','Residential','Permit Type',\n",
    "                                           'Oil Gas','Issuance Date'],dtype={'BOROUGH':str,\n",
    "                                                                           'Block':str,\n",
    "                                                                           'Lot':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# race data\n",
    "race = pd.read_csv(CENSUS_TRACT_RACE,skiprows=[1],usecols=['GEO.id2', 'HC01_VC03', \n",
    "                                                           'HC01_VC49', 'HC01_VC50', \n",
    "                                                           'HC01_VC51','HC01_VC56', \n",
    "                                                           'HC01_VC64', 'HC01_VC69', 'HC01_VC23'])\n",
    "\n",
    "# rename columns\n",
    "race.rename(columns={'HC01_VC03': 'TOTAL_POPULATION', 'HC01_VC49': 'WHITE',\n",
    "                        'HC01_VC50': 'BLACK_AFRICAN_AMERICAN', 'HC01_VC51': 'AMERICAN_INDIAN_AND_ALASKA_NATIVE',\n",
    "                        'HC01_VC56': 'ASIAN', 'HC01_VC64': 'NATIVE_HAWAIIAN_AND_OTHER_PACIFIC_ISLANDER',\n",
    "                        'HC01_VC69': 'SOME_OTHER_RACE', 'HC01_VC23': 'MEDIAN_AGE', 'GEO.id2': 'GEOID'}, inplace=True)\n",
    "\n",
    "# convert values to float\n",
    "def make_float(expected_float):\n",
    "    try:\n",
    "        if type(expected_float) == str:\n",
    "            expected_float = expected_float.replace('+', '').replace(',', '')\n",
    "        return float(expected_float)\n",
    "    except:\n",
    "        # print expected_float\n",
    "        return np.nan\n",
    "\n",
    "for i in race.columns[race.columns!='GEOID']:\n",
    "    race[i] = race[i].apply(lambda x: make_float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# income data\n",
    "income = pd.read_csv(CENSUS_TRACT_INCOME,skiprows=[1],usecols=['GEO.id2', 'HC01_EST_VC01', 'HC01_EST_VC15'])\n",
    "\n",
    "# rename columns\n",
    "income.rename(columns={'HC01_EST_VC01': 'TOTAL_HOUSEHOLDS', \n",
    "                       'HC01_EST_VC15': 'MEAN_INCOME', 'GEO.id2': 'GEOID'}, inplace=True)\n",
    "\n",
    "#convert values to float\n",
    "for i in income.columns[income.columns!='GEOID']:\n",
    "    income[i] = income[i].apply(lambda x: make_float(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter, aggregate and scale data\n",
    "\n",
    "- Filter FDNY by gas leaks\n",
    "- Aggregate FDNY by zip codes\n",
    "- Preprocess and scale PLUTO attributes\n",
    "- Aggregate PLUTO data by zip\n",
    "- Preprocess and scale building data attributes\n",
    "- Aggregate building data by zip \n",
    "- Aggregate census tract data by zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter FDNY for gas leaks and aggregate by zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split incident description to get code, filter\n",
    "def code_split(data):\n",
    "    a = data.split(' -')\n",
    "    return a[0]\n",
    "\n",
    "fdny['incident_code'] = fdny.INCIDENT_TYPE_DESC.apply(lambda x: code_split(x))\n",
    "fdny_gas = fdny[fdny.incident_code=='412']\n",
    "\n",
    "# clean FDNY zip data and aggregate by zip\n",
    "fdny_gas_zip = pd.DataFrame(fdny_gas.groupby('ZIP_CODE')[\n",
    "        'IM_INCIDENT_KEY'].count()).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess and scale PLUTO attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert PLUTO zip to string\n",
    "master_pluto['ZipCode'] = master_pluto['ZipCode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate building age\n",
    "def year_calc(data):\n",
    "    if (data < 1800) | (data > 2016):\n",
    "        return float('NaN')\n",
    "    else:\n",
    "        return 2017-data\n",
    "\n",
    "master_pluto['age'] = master_pluto.YearBuilt.apply(lambda x: year_calc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_and_group_zip(data,zip_col_name,field,multiple=True,\n",
    "                        header_prefix=None,dispose=False,og=False):\n",
    "    '''Creates a general \"group by\" and scaling function that:\n",
    "    - groups data for a given variable category in an input dataframe by zip code\n",
    "    - then creates a ratio of each variable category in the zip for all values in zip\n",
    "    - produces a new sparse matrix with rows=zip codes and cols=each category of the variable,\n",
    "    where the values are the ratio of the category / all instances in the zip\n",
    "    '''\n",
    "    # group selected variable by zip code\n",
    "    if multiple:\n",
    "        if og:\n",
    "            data2 = data.copy()\n",
    "            data2[field] = data2[field].fillna('NA')\n",
    "            data = data2.copy()\n",
    "        \n",
    "        temp_df = data.groupby([zip_col_name,field])[\n",
    "            field].count().unstack(level=-1).reset_index()\n",
    "        \n",
    "        # create df of ratio of select category of variable per all instances in zip\n",
    "        zip_matrix = pd.DataFrame()\n",
    "\n",
    "        for i in range(len(temp_df[zip_col_name])):\n",
    "            zip_matrix[str(\n",
    "                temp_df[zip_col_name][i])] = temp_df.T[i][1:]/temp_df.T[i][1:].sum()\n",
    "    \n",
    "        zip_matrix = zip_matrix.T.reset_index()\n",
    "\n",
    "        zip_matrix['ZipCode'] = zip_matrix['index'].astype(str)\n",
    "        if og:\n",
    "            zip_matrix = zip_matrix.drop(['index','NA'],axis=1)\n",
    "        else:\n",
    "            zip_matrix = zip_matrix.drop('index',axis=1)\n",
    "        \n",
    "        if dispose:\n",
    "            zip_matrix = zip_matrix.rename(columns={zip_matrix.columns[0]:'No_disposition'})\n",
    "            \n",
    "        # catch decimal zipcodes and strip\n",
    "        if len(zip_matrix.ZipCode[10])>5:\n",
    "            zip_matrix['ZipCode'] = zip_matrix['ZipCode'].apply(lambda x: x[:-2])\n",
    "\n",
    "        \n",
    "        # update header to specific source data (for less confusion when merging data later)\n",
    "        if header_prefix:\n",
    "            new_columns = []\n",
    "            for col in zip_matrix.columns:\n",
    "                if col != 'ZipCode':\n",
    "                    new_columns.append(header_prefix+col)\n",
    "                else:\n",
    "                    new_columns.append(col)\n",
    "            zip_matrix.columns = new_columns\n",
    "            \n",
    "        return zip_matrix       \n",
    "    \n",
    "    else:\n",
    "    \n",
    "        return pd.DataFrame((data.groupby(zip_col_name)[field].sum())/data.groupby(\n",
    "                zip_col_name)[field].count()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# groupby zip - average age\n",
    "avg_bldg_age_by_zip = scale_and_group_zip(master_pluto,'ZipCode','age',multiple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# groupby zip - # building class in zip / total building in zip\n",
    "bldgclass_by_zip = scale_and_group_zip(master_pluto,'ZipCode','BldgClass',\n",
    "                                       multiple=True,header_prefix='bldg_class_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# groupby zip - # landuse in zip / total land uses in zip\n",
    "landuse_by_zip = scale_and_group_zip(master_pluto,'ZipCode','LandUse',\n",
    "                                       multiple=True,header_prefix='landuse_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the following assorted pluto attributes are aggregated by zip\n",
    "pluto_attrib_by_zip = pd.DataFrame()\n",
    "\n",
    "# function to create ratio of given PLUTO category per zip code\n",
    "def pluto_attributes_zip(data,zip_col_name,oldfield,newfield,denominator='BldgArea'):\n",
    "    pluto_attrib_by_zip[newfield] = data.groupby(\n",
    "        zip_col_name)[oldfield].sum()*1.0/data.groupby(zip_col_name)[denominator].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# commercial ratio by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','ComArea','com_ratio',denominator='BldgArea')\n",
    "\n",
    "# residential ratio by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','ResArea','res_ratio',denominator='BldgArea')\n",
    "\n",
    "# office ratio by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','OfficeArea','office_ratio',denominator='BldgArea')\n",
    "\n",
    "# retail ratio by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','RetailArea','retail_ratio',denominator='BldgArea')\n",
    "\n",
    "# res / total units by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','UnitsRes','res_unit_ratio',denominator='UnitsTotal')\n",
    "\n",
    "# mean unit area by zip code\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','BldgArea','unit_area',denominator='UnitsTotal')\n",
    "\n",
    "# assessed value per sq foot\n",
    "pluto_attributes_zip(master_pluto,'ZipCode','AssessTot','value_per_ft',denominator='LotArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total units by zip code\n",
    "pluto_attrib_by_zip['total_units'] = master_pluto.groupby('ZipCode')['UnitsTotal'].sum()\n",
    "\n",
    "# reset index\n",
    "pluto_attrib_by_zip = pluto_attrib_by_zip.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess and scale the DOB and ECB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge BIN with zipcodes pulled from another dataset\n",
    "pad = pd.read_csv(PAD,usecols=['bin','zipcode'])\n",
    "# zip to int\n",
    "def zipint(data):\n",
    "    try:\n",
    "        return str(int(data))\n",
    "    except ValueError:\n",
    "        return float('NaN')\n",
    "pad['zipcode'] = pad.zipcode.apply(lambda x: zipint(x))\n",
    "pad = pad.rename(columns={'bin':'BIN'})\n",
    "pad = pad[~pad.zipcode.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge zip to dob/ecb datasets\n",
    "dob_complaints = dob_complaints.merge(pad,how='left',on='BIN')\n",
    "dob_violations = dob_violations.merge(pad,how='left',on='BIN')\n",
    "ecb = ecb.merge(pad,how='left',on='BIN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice DOB data to include only data before 12/31/2015, same as FDNY data for now, we'll consider issuances before 1/1/2013 to be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert date string to datetime\n",
    "dob_complaints['date_entered'] = dob_complaints['Date Entered'].apply(\n",
    "    lambda x: datetime.datetime.strptime(x,'%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "permits['issuance_date'] = permits['Issuance Date'].apply(\n",
    "    lambda x: datetime.datetime.strptime(x,'%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deal with inconsistent datetime\n",
    "def dob_date(data):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(data, '%Y%m%d')\n",
    "    except:\n",
    "        try:\n",
    "            y,md = data.split('  ')\n",
    "            if y in ['11','12','13','14','15']:\n",
    "                data = '20'+y+md\n",
    "                return datetime.datetime.strptime(data, '%Y%m%d')\n",
    "        except:\n",
    "            try:\n",
    "                data = str(data)[:8]\n",
    "                return datetime.datetime.strptime(data, '%Y%m%d')\n",
    "            except:\n",
    "                return float(\"NaN\")\n",
    "\n",
    "dob_violations['issue_date'] = dob_violations['ISSUE_DATE'].apply(\n",
    "    lambda x: dob_date(x))\n",
    "\n",
    "# cut out the approx 50 records with incoherent date format\n",
    "dob_violations = dob_violations[~dob_violations['issue_date'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deal with inconsistent datetime\n",
    "def ecb_date(data):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(str(data), '%Y%m%d')\n",
    "    except:\n",
    "        return float(\"NaN\")\n",
    "\n",
    "ecb['issue_date'] = ecb['ISSUE_DATE'].apply(\n",
    "    lambda x: ecb_date(x))\n",
    "\n",
    "# cut out the 85 records with incoherent date format\n",
    "ecb = ecb[~ecb['issue_date'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# truncate dates after 12/31/2015, but keeping dates prior\n",
    "dob_complaints = dob_complaints[dob_complaints.date_entered<'2016-01-01']\n",
    "\n",
    "dob_violations = dob_violations[dob_violations.issue_date<datetime.datetime(2016,1,1,0,0)]\n",
    "\n",
    "ecb = ecb[ecb.issue_date<datetime.datetime(2016,1,1,0,0)]\n",
    "\n",
    "permits = permits[permits.issuance_date<datetime.datetime(2016,1,1,0,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process DOB/ECB data as with the PLUTO data (group by zip and scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same as above, group various DOB / ECB datasets to zip and scale\n",
    "\n",
    "# groupby zip - # complaint category in zip / total complaints in zip\n",
    "complaints_by_zip = scale_and_group_zip(dob_complaints,'zipcode','Complaint Category',\n",
    "                                       multiple=True,header_prefix='DOB_complaint_')\n",
    "\n",
    "# groupby zip - # disposition code in zip / total dispositions in zip\n",
    "disposition_by_zip = scale_and_group_zip(dob_complaints,'zipcode','Disposition Code',\n",
    "                                       multiple=True,header_prefix='DOB_dispos_',dispose=True)\n",
    "\n",
    "# groupby zip - # dob violations type in zip / total violations in zip\n",
    "violations_by_zip = scale_and_group_zip(dob_violations,'zipcode','VIOLATION_TYPE',\n",
    "                                       multiple=True,header_prefix='DOB_violation_')\n",
    "\n",
    "# groupby zip - # ecb violation type in zip / total violations in zip\n",
    "ecb_violations_by_zip = scale_and_group_zip(ecb,'zipcode','VIOLATION_TYPE',\n",
    "                                      multiple=True,header_prefix='ECB_violation_')\n",
    "\n",
    "# groupby zip - # ecb violation type in zip / total violations in zip\n",
    "ecb_infractions_by_zip = scale_and_group_zip(ecb,'zipcode','INFRACTION_CODE1',\n",
    "                                       multiple=True,header_prefix='ECB_infraction_')\n",
    "\n",
    "# groupby zip - # permit type in zip / total permits in zip\n",
    "permit_by_zip = scale_and_group_zip(permits,'Zip Code','Permit Type',\n",
    "                                       multiple=True,header_prefix='DOB_permit_')\n",
    "\n",
    "# groupby zip - # oil or gas permits in zip / total permits in zip\n",
    "oil_gas_permit_by_zip = scale_and_group_zip(permits,'Zip Code','Oil Gas',\n",
    "                                       multiple=True,header_prefix='DOB_permit_',og=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process census data and aggregate by zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge race and income\n",
    "census = race.merge(income,how='outer',on='GEOID')\n",
    "\n",
    "# add zip code column\n",
    "census['TRACT'] = census.GEOID.apply(lambda x: str(x))\n",
    "\n",
    "census_zip = census.merge(zip_tract_nyc,how='inner',on='TRACT')\n",
    "\n",
    "census_zip.rename(columns={'ZIPCODE':'zipcode'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the following assorted census attributes are aggregated by zip\n",
    "census_features_by_zip = pd.DataFrame()\n",
    "\n",
    "# function to create ratio of given PLUTO category per zip code\n",
    "def agg_census_zip(data,zip_col_name,oldfield,newfield,denominator='TOTAL_POPULATION'):\n",
    "    census_features_by_zip[newfield] = data.groupby(\n",
    "        zip_col_name)[oldfield].sum()*1.0/data.groupby(zip_col_name)[denominator].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same as above, group various census data to zip and scale\n",
    "\n",
    "# groupby zip: total population in zip\n",
    "census_features_by_zip['total_population'] = census_zip.groupby('zipcode')['TOTAL_POPULATION'].sum()\n",
    "\n",
    "# groupby zip: total households in zip\n",
    "census_features_by_zip['total_households'] = census_zip.groupby('zipcode')['TOTAL_HOUSEHOLDS'].sum()\n",
    "\n",
    "# demo data by zip: race population / total population of zip\n",
    "for col in census_zip.columns[3:9]:\n",
    "    agg_census_zip(census_zip,'zipcode',col,col+'_ratio','TOTAL_POPULATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# aggregate income by mutliplying mean income for census tract by total households in tract\n",
    "# to get total projected income for the tract\n",
    "# then aggregate total income to zipcode level and divide that by total households aggregated to zip\n",
    "# to get a mean income per household for the zip\n",
    "\n",
    "census_zip['total_income'] = census_zip['MEAN_INCOME']*census_zip['TOTAL_HOUSEHOLDS']\n",
    "\n",
    "census_features_by_zip['zip_household_mean_income'] = census_zip.groupby(\n",
    "    'zipcode')['total_income'].sum()*1.0/census_zip.groupby('zipcode')['TOTAL_HOUSEHOLDS'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set zipcode as column for later merge\n",
    "\n",
    "census_features_by_zip.reset_index(inplace=True)\n",
    "census_features_by_zip = census_features_by_zip.rename(columns={'zipcode':'ZipCode'}).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the NYC zipcode shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove duplicate zips (just keeping first listed)\n",
    "index_list = []\n",
    "for i in nyc_zips.ZIPCODE:\n",
    "    temp_index = nyc_zips.ZIPCODE[nyc_zips.ZIPCODE==i].index.tolist()\n",
    "\n",
    "    if len(temp_index)>1:\n",
    "        index_list += temp_index[1:]\n",
    "\n",
    "index_list = set(index_list)\n",
    "\n",
    "zip_t = nyc_zips.T\n",
    "\n",
    "zip_drop = zip_t.drop(index_list,axis=1)\n",
    "\n",
    "nyc_zips_set = zip_drop.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge gas\n",
    "fdny_gas_zip['ZipCode'] = fdny_gas_zip['ZIP_CODE'].astype(str)\n",
    "fdny_gas_zip['gas_incidents'] = fdny_gas_zip['IM_INCIDENT_KEY']\n",
    "fdny_gas_zip_2 = fdny_gas_zip.drop(['ZIP_CODE','IM_INCIDENT_KEY'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, since FDNY zips are a subset of PLUTO zips, merging all PLUTO first, then performing left-join of FDNY on PLUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge PLUTO datasets\n",
    "\n",
    "# age and building class\n",
    "merged_pluto = avg_bldg_age_by_zip.merge(bldgclass_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# merge land use\n",
    "merged_pluto = merged_pluto.merge(landuse_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# merge remaing PLUTO attributes\n",
    "merged_pluto = merged_pluto.merge(pluto_attrib_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# merge with FDNY\n",
    "pluto_fdny = merged_pluto.merge(fdny_gas_zip_2, how = 'left',on='ZipCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge DOB / ECB data\n",
    "\n",
    "# dob complaints\n",
    "pluto_fdny_dob = pluto_fdny.merge(complaints_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# dob dispositions\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(disposition_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# dob violations\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(violations_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# ecb violations\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(ecb_violations_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# ecb infractions\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(ecb_infractions_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# dob permit type\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(permit_by_zip,how='left',on='ZipCode')\n",
    "\n",
    "# dob oil or gas permit\n",
    "pluto_fdny_dob = pluto_fdny_dob.merge(oil_gas_permit_by_zip,how='left',on='ZipCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge census data\n",
    "pluto_fdny_dob_census = pluto_fdny_dob.merge(census_features_by_zip,how='left',on='ZipCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge zip shapefiles\n",
    "nyc_zips_set['ZipCode'] = nyc_zips_set['ZIPCODE'].astype(str)\n",
    "nyc_zips_clean = nyc_zips_set[['ZipCode','geometry','AREA']].copy()\n",
    "\n",
    "master_merged = pluto_fdny_dob_census.merge(nyc_zips_clean,how='left',on='ZipCode')\n",
    "\n",
    "# move target (i.e. dependent) variable to last column and rename \"total_gas_incidents\"\n",
    "master_merged['total_gas_incidents'] = master_merged['gas_incidents']\n",
    "del master_merged['gas_incidents']\n",
    "\n",
    "# add column gas incidents per building unit\n",
    "master_merged['gas_incidents_per_bldg_unit'] = master_merged['total_gas_incidents']*1.0/master_merged['total_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_merged.to_csv('processed_data/pluto_fdny_dob_census_to_zipcode.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT: final merged \n",
    "\n",
    "#### FDNY\n",
    "- Merge with zip code shapefile\n",
    "\n",
    "#### PLUTO features\n",
    "- Avg building age per zipcode\n",
    "- Ratio of each building class per zip code\n",
    "- Ratio of each land use per zip code\n",
    "- Building use ratio (commercial, residential, office, retail) per zip code\n",
    "- Residential unit density per zip code\n",
    "- Ave Unit area per zip code\n",
    "- Value per ft per zip code\n",
    "- Total units per zip code\n",
    "\n",
    "#### DOB/ECB features\n",
    "- Ratio of each DOB complaint type per zip code\n",
    "- Ratio of each DOB complaint disposition per zip code\n",
    "- Ratio of each DOB violation type per zip code\n",
    "- Ratio of each ECB violation type per zip code\n",
    "- Ratio of each DOB work permit type per zip code\n",
    "- Ratio of oil or gas permits out of all permits per zip code\n",
    "\n",
    "#### Census data features\n",
    "- Total population per zip code\n",
    "- Total households per zip code\n",
    "- Mean income (calculated by: mean income per census tract * total households in ct to get total income per ct, \n",
    "    then aggregate total income to zip code and divide by total households aggregated to zip code\n",
    "- Ratio of various racial groups out of total population per zip code\n",
    "\n",
    "#### Target variables (last two columns in the output dataset)\n",
    "- Total gas incidents per zip code\n",
    "- Ratio of gas incidents per total building units in zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
